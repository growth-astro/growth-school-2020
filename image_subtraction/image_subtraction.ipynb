{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Subtraction Module\n",
    "\n",
    "**Lecturer:** Christoffer Fremling<br>\n",
    "**Jupyter Notebook Authors:** Igor Andreoni, Christoffer Fremling and Cameron Hummels\n",
    "\n",
    "This is a Jupyter notebook lesson taken from the GROWTH Summer School 2019.  For other lessons and their accompanying lectures, please see: http://growth.caltech.edu/growth-school-2019.html\n",
    "\n",
    "## Objective\n",
    "Learn how to perform image subtraction to discover astronomical transients from multiple consecutive images.\n",
    "\n",
    "## Key steps\n",
    "- Register science and reference images (make them aligned and of the same size)\n",
    "- PSF extraction, using PSFex\n",
    "- PSF matching by convolution\n",
    "- [Zero-point calibration]\n",
    "- Image subtraction\n",
    "\n",
    "## Required dependencies\n",
    "\n",
    "See GROWTH school webpage for detailed instructions on how to install these modules and packages.  Nominally, you should be able to install the python modules with `pip install <module>`.  The external astromatic packages are easiest installed using package managers (e.g., `rpm`, `apt-get`).\n",
    "\n",
    "### Python modules\n",
    "* python 3\n",
    "* astropy\n",
    "* numpy\n",
    "* scipy\n",
    "* matplotlib\n",
    "* pytest\n",
    "* photutils\n",
    "\n",
    "### External packages\n",
    "* SWarp https://www.astromatic.net/software\n",
    "* SExtractor https://www.astromatic.net/software\n",
    "* PSFex https://www.astromatic.net/software\n",
    "* ds9 http://ds9.si.edu/site/Home.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant packages\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits #FITS files handling\n",
    "import os  #Call commands from outside Python\n",
    "from astropy.io import ascii  #Read/write ascii files\n",
    "\n",
    "# Useful to smooth the images with a Gaussian kernel before the subtraction\n",
    "from scipy.signal import convolve as scipy_convolve\n",
    "from astropy.convolution import convolve \n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "\n",
    "# Background subtraction\n",
    "from astropy.stats import SigmaClip\n",
    "from photutils import Background2D, MedianBackground\n",
    "from photutils import make_source_mask\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Running external programs\n",
    "import subprocess\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dependencies\n",
    "\n",
    "In order for this jupyter notebook to function correctly, we must have some external software installed, as described above.  The following step assures that these are installed properly before getting to the rest of the content of this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_dependency(dep, alternate_name=None):\n",
    "    \"\"\"\n",
    "    Test external dependency by trying to run it as a subprocess\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subprocess.check_output(dep, stderr=subprocess.PIPE, shell=True)\n",
    "        print(\"%s is installed properly as %s. OK\" % (dep, dep))\n",
    "        return 1\n",
    "    except subprocess.CalledProcessError:\n",
    "        try:\n",
    "            subprocess.check_output(alternate_name, stderr=subprocess.PIPE, shell=True)\n",
    "            print(\"%s is installed properly as %s. OK\" % (dep, alternate_name))\n",
    "            return 1\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"===%s/%s IS NOT YET INSTALLED PROPERLY===\" % (dep, alternate_name))\n",
    "            return 0\n",
    "    \n",
    "dependencies = [('sextractor', 'sex'), ('SWarp', 'swarp'), ('psfex', 'PSFEx'), ('ds9', 'DS9')]\n",
    "i = 0\n",
    "for dep_name1, dep_name2 in dependencies:\n",
    "    i += test_dependency(dep_name1, dep_name2)\n",
    "print(\"%i out of %i external dependencies installed properly.\\n\" % (i, len(dependencies)))\n",
    "if i != len(dependencies):\n",
    "    print(\"Please correctly install these programs before continuing by following the instructions in README.md.\")\n",
    "else:\n",
    "    print(\"You are ready to continue.\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up paths and clear old temp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove temporary fits files in current working directory\n",
    "[os.remove(f) for f in os.listdir() if f.endswith('.fits')]\n",
    "\n",
    "# Set directory structure\n",
    "cwd = os.getcwd()\n",
    "proc_dir = os.path.join(cwd, 'processed')\n",
    "data_dir = os.path.join(cwd, 'data')\n",
    "out_dir = os.path.join(proc_dir, 'out')\n",
    "if os.path.isdir(proc_dir): \n",
    "    shutil.rmtree(proc_dir)\n",
    "os.mkdir(proc_dir)\n",
    "\n",
    "for f in os.listdir(data_dir):\n",
    "    shutil.copy2(os.path.join(data_dir, f), os.path.join(proc_dir, f))\n",
    "os.chdir(proc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference and science images\n",
    "\n",
    "Define the reference and science images. Open them with ds9 to give them a look. <br />\n",
    "Also, what is the size of the images in pixel?  This information will be useful when we want to align the images using Swarp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference image\n",
    "ref_image_name = os.path.join(data_dir, 'refimg_i.fits')\n",
    "ref_image = fits.open(ref_image_name)\n",
    "\n",
    "#Plot up the reference image\n",
    "mean, median, std = sigma_clipped_stats(ref_image[0].data)\n",
    "plt.figure(figsize=(8,8))\n",
    "#set the scale of the image based on its statistics\n",
    "plt.imshow(ref_image[0].data, vmin = median - 2*std, vmax = median + 2*std)\n",
    "plt.colorbar()\n",
    "plt.title('Reference image')\n",
    "plt.show()\n",
    "\n",
    "#Image size?\n",
    "print(\"The dimension of the X axis of the reference image is \")\n",
    "print(ref_image[0].header[\"NAXIS1\"])\n",
    "print(\"The dimension of the Y axis of the reference image is \")\n",
    "print(ref_image[0].header[\"NAXIS2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "Let's do the same for the science image.  Can you already spot the Supernova? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Science image\n",
    "sci_image_name = os.path.join(data_dir, '20120419094409p.fits')\n",
    "sci_image = fits.open(sci_image_name)\n",
    "\n",
    "#Open the images \n",
    "##os.system('ds9 -zscale '+sci_image_name +' ' + ref_image_name +'&')\n",
    "\n",
    "#Plot up the science image\n",
    "mean, median, std = ???\n",
    "plt.figure(figsize=(8,8))\n",
    "#set the scale of the image based on its statistics\n",
    "???\n",
    "plt.title('Science image')\n",
    "plt.show()\n",
    "\n",
    "#Image size?\n",
    "print(\"The dimension of the X axis of the science image is \")\n",
    "???\n",
    "print(\"The dimension of the Y axis of the science image is \")\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align the images\n",
    "\n",
    "Use the AstrOmatic Swarp package to align the images.  Swarp relies on the astrometric information of the image (in other words, on the sky coordinates), therefore both the science and reference images must be astrometrically calibrated (for example, using the AstrOmatic SCAMP package).  In this module we assume that the input images are already calibrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Swarp command\n",
    "try:\n",
    "    command = \"SWarp %s %s -c %s -SUBTRACT_BACK N -RESAMPLE Y -RESAMPLE_DIR . -COMBINE N -IMAGE_SIZE 1800,900\" % (sci_image_name, ref_image_name, os.path.join(data_dir, 'config.swarp'))\n",
    "    print('Executing command: %s' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run SWarp with exit error %s'%err)\n",
    "\n",
    "#Names of the aligned images\n",
    "sci_image_aligned_name = sci_image_name.replace(\".fits\", \".resamp.fits\").replace('data','processed')\n",
    "ref_image_aligned_name = ref_image_name.replace(\".fits\", \".resamp.fits\").replace('data','processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "If we attempt an image subtraction now, what does the result look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test image subtraction:\n",
    "ref_image_aligned = fits.open(ref_image_aligned_name)\n",
    "hdr_ref = ref_image_aligned[0].header #save fits header\n",
    "sci_image_aligned = fits.open(sci_image_aligned_name)\n",
    "hdr_sci = sci_image_aligned[0].header #save fits header\n",
    "\n",
    "#Perform the image subtraction\n",
    "image_sub = ???\n",
    "hdu_image_sub = fits.PrimaryHDU(image_sub)\n",
    "hdu_image_sub.writeto(\"sub_test_0.fits\", overwrite = True)\n",
    "\n",
    "#Plot up the result of the image subtraction\n",
    "mean, median, std = sigma_clipped_stats(hdu_image_sub.data)\n",
    "plt.figure(figsize=(8,8))\n",
    "#set the scale of the image based on its statistics\n",
    "plt.imshow(hdu_image_sub.data, vmin = median - 2*std, vmax = median + 2*std, cmap='gray')\n",
    "plt.colorbar(shrink = 0.4)\n",
    "plt.title('Test image subtraction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Subtraction\n",
    "- Mask sources in images\n",
    "- Use 3 sigma clipping, 15 iterations to filter data and accurately measure the backgorund\n",
    "- Then split image into 300x300 pixel boxes and apply 2x2 median filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Background subtraction.  Import the relevant packages\n",
    "from astropy.stats import SigmaClip\n",
    "from photutils import Background2D, MedianBackground\n",
    "from photutils import make_source_mask\n",
    "mask_sci = make_source_mask(sci_image_aligned[0].data, snr=2, npixels=3, dilate_size=11)\n",
    "mask_ref = make_source_mask(ref_image_aligned[0].data, snr=2, npixels=3, dilate_size=11)\n",
    "\n",
    "sci_image_aligned_name = os.path.join(proc_dir, \"bg_sub_sci.fits\")\n",
    "ref_image_aligned_name = os.path.join(proc_dir, \"bg_sub_ref.fits\")\n",
    "\n",
    "# remove temporary fits files\n",
    "if os.path.exists(sci_image_aligned_name): os.remove(sci_image_aligned_name)\n",
    "if os.path.exists(ref_image_aligned_name): os.remove(ref_image_aligned_name)\n",
    "\n",
    "sigma_clip = SigmaClip(sigma=3, iters=15) # Sigma clipping\n",
    "bkg_estimator = MedianBackground()\n",
    "bkg_sci = Background2D(sci_image_aligned[0].data, (200, 150), filter_size=(3, 3), sigma_clip=sigma_clip, bkg_estimator=bkg_estimator, mask=mask_sci)\n",
    "bkg_ref = Background2D(ref_image_aligned[0].data, (200, 150), filter_size=(3, 3), sigma_clip=sigma_clip, bkg_estimator=bkg_estimator, mask=mask_ref)\n",
    "\n",
    "#Remove the background from the science image\n",
    "sci_image_aligned[0].data = sci_image_aligned[0].data-bkg_sci.background\n",
    "hdu_image_sub = fits.PrimaryHDU(sci_image_aligned[0].data-bkg_sci.background)\n",
    "hdu_image_sub.writeto(sci_image_aligned_name)\n",
    "\n",
    "#Remove the background from the reference image\n",
    "ref_image_aligned[0].data = ref_image_aligned[0].data-bkg_ref.background\n",
    "hdu_image_sub = fits.PrimaryHDU(ref_image_aligned[0].data-bkg_ref.background)\n",
    "hdu_image_sub.writeto(ref_image_aligned_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the background-subtracted images look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display with ds9\n",
    "try:\n",
    "    command = \"ds9 %s %s\" % (sci_image_aligned_name, ref_image_aligned_name)\n",
    "    print('Executing command: %s' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run ds9 with exit error %s'%err)\n",
    "\n",
    "#Plot here the background image\n",
    "plt.imshow(bkg_sci.background, origin='lower', cmap='Greys_r')\n",
    "#plt.imshow(sci_image_aligned[0].data-bkg_sci.background, origin='lower', cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSF matching\n",
    "\n",
    "The atmosphere heavily affects the PSF of the images by determining the \"seeing\" conditions. The seeing for ground-based optical telescopes is usually measured as the FWHM of the imaging PSF.  Properties of the atmosphere can change very rapidly, so it is rare that science and reference images are characterized by the same seeing. Therefore their PSFs are usually different, which is a problem for image subtraction. \n",
    "\n",
    "\n",
    "### Generate the kernel for the convolution\n",
    "\n",
    "The PSF of the science and reference images can be matched in several different ways.  Here we start by performing a first source extraction on both the science image.  We can use the catalogs of sources that we obtain for two main purposes: <br />\n",
    "1. Measure the PSF of the science frame, using PSFex or photutils\n",
    "2. Obtain instruments magnitudes that will be the basis for the zero-point calibration (see Photometry module).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists('prepsfex.cat'): #Remove possible temporary files\n",
    "    os.remove(\"prepsfex.cat\") \n",
    "try:\n",
    "    command = \"sextractor %s -c %s -CATALOG_NAME %s -MAG_ZEROPOINT 25.0\" % (sci_image_aligned_name, os.path.join(data_dir, 'prepsfex.sex'), os.path.join(data_dir, 'prepsfex.cat'))\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run SExtractor with exit error %s'%err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use another software part of the AstrOmatic suite, PSFex, to measure the PSF of the science image. PSFex estimates the PSF based on the information present in the catalog generated with SExtractor.  Then, let's plot the PSF model obtained with PSFex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run PSFex to compute PSF, read and display the final model; needs to output to \"out\" dir.\n",
    "if not os.path.isdir('out'): os.mkdir('out')\n",
    "shutil.copy2(os.path.join(data_dir, 'prepsfex.cat'), os.path.join(proc_dir, 'prepsfex.cat'))\n",
    "\n",
    "try:\n",
    "    command = \"psfex prepsfex.cat -c psfex_conf.psfex\"\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run psfex with exit error %s'%err)\n",
    "\n",
    "psf_sci_image_name = os.path.join(out_dir,'proto_prepsfex.fits')\n",
    "print(psf_sci_image_name)\n",
    "psf_sci_image = fits.open(psf_sci_image_name)\n",
    "\n",
    "plt.imshow(psf_sci_image[0].data[0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolve the reference image with the PSF of the science image\n",
    "Now that the kernel is generated, let's convolve the reference image with the PSF of the science frame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolve the reference image with the PSF of the science frame\n",
    "if os.path.exists(os.path.join(proc_dir, 'ref_convolved.fits')): \n",
    "    os.remove(os.path.join(proc_dir, 'ref_convolved.fits'))\n",
    "\n",
    "kernel_sci = psf_sci_image[0].data[0]\n",
    "ref_image_aligned = fits.open(ref_image_aligned_name)\n",
    "ref_conv = scipy_convolve(ref_image_aligned[0].data, kernel_sci, mode='same', method='fft')\n",
    "\n",
    "#Create a new fits file for the convolved image\n",
    "hdu_ref_conv = fits.PrimaryHDU(ref_conv,hdr_ref)\n",
    "hdu_ref_conv.writeto(os.path.join(proc_dir, \"ref_convolved.fits\"))\n",
    "\n",
    "#Plot up the convolved reference image\n",
    "mean, median, std = sigma_clipped_stats(hdu_ref_conv.data)\n",
    "plt.figure(figsize=(8,8))\n",
    "#set the scale of the image based on its statistics\n",
    "plt.imshow(hdu_ref_conv.data, vmin = median - 2*std, vmax = median + 2*std)\n",
    "plt.colorbar(shrink = 0.4)\n",
    "plt.title('Convolved reference image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolve the science image with the PSF of the reference image\n",
    "\n",
    "### Exercise:\n",
    "\n",
    "Same as above, but this time we generate a kernel with the properties of the PSF of the reference image.  Then, we convolve the science image with this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SExtractor command for the ref image\n",
    "if os.path.exists('prepsfex.cat'): \n",
    "    os.remove(\"prepsfex.cat\")\n",
    "\n",
    "try:\n",
    "    command = \"???\"\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run SExtractor with exit error %s'%err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run PSFex to compute PSF, read and display the final model \n",
    "if os.path.exists(os.path.join(out_dir,'proto_prepsfex.fits')): \n",
    "    os.remove(os.path.join(out_dir, 'proto_prepsfex.fits'))\n",
    "shutil.copy2(os.path.join(data_dir, 'prepsfex.cat'), os.path.join(proc_dir, 'prepsfex.cat'))\n",
    "\n",
    "try:\n",
    "    command = \"???\"\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run psfex with exit error %s'%err)\n",
    "\n",
    "psf_ref_image_name = os.path.join(out_dir, 'proto_prepsfex.fits')\n",
    "psf_ref_image = fits.open(psf_ref_image_name)\n",
    "\n",
    "plt.imshow(psf_ref_image[0].data[0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_ref = psf_ref_image[0].data[0]\n",
    "\n",
    "# Read the SCIENCE image and convolve it with the PSF of the reference frame\n",
    "sci_image_aligned = fits.open(sci_image_aligned_name)\n",
    "sci_conv = ???\n",
    "\n",
    "#Create a new fits file for the convolved image\n",
    "hdu_sci_conv = fits.PrimaryHDU(sci_conv,hdr_sci)\n",
    "hdu_sci_conv.writeto(\"sci_convolved.fits\", overwrite = True)\n",
    "\n",
    "#Plot up the convolved science image\n",
    "mean, median, std = sigma_clipped_stats(hdu_sci_conv.data)\n",
    "plt.figure(figsize=(8,8))\n",
    "#set the scale of the image based on its statistics\n",
    "plt.imshow(hdu_sci_conv.data, vmin = median - 2*std, vmax = median + 2*std)\n",
    "plt.colorbar(shrink = 0.4)\n",
    "plt.title('Convolved science image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the alignment\n",
    "Now that the science image is convolved with (an approximation of) the PSF of the reference image, \n",
    "and the reference image is convolved with the PSF of the science image, we can perform the image subtraction.\n",
    "\n",
    "- Before the subtraction we use an fft method (chi_2_shift) to fine-tune the image alignment of the reference and science image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from image_registration import chi2_shift\n",
    "from image_registration.fft_tools import shift\n",
    "import scipy\n",
    "from scipy import ndimage, misc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.fft\n",
    "\n",
    "# Fine tuning of image alignment\n",
    "xoff, yoff, exoff, eyoff = chi2_shift(ref_conv, sci_conv, 10, return_error=True, upsample_factor='auto')\n",
    "print(\"Alignment offsets:\",xoff,yoff)\n",
    "\n",
    "sci_conv_shift = scipy.ndimage.shift(sci_conv, [-yoff, -xoff], order=3, mode='reflect', cval=0.0, prefilter=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of the images\n",
    "\n",
    "The science and reference images are usually obtained with different exposure times.  In addition, the reference image can be the stack of several images to increase the depth.  Finally, different CCDs of the same camera (or even different regions of the same CCD when multiple amplifiers are present) may have slightly different gain. <br >\n",
    "\n",
    "The background subtraction should have removed the non-linear offsets between science and reference images.  We can therefore normalize the two images by computing the ratio of bright star fluxes in the two images. Once again, we use SExtractor to extract the flux and other quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images using the stars in the image\n",
    "\n",
    "#Run SExtractor on the science image\n",
    "sextractor_command = \"sextractor sci_convolved.fits -c prepsfex.sex -CATALOG_NAME sci_match.cat -MAG_ZEROPOINT 25.0 -CATALOG_TYPE=ASCII_HEAD\"\n",
    "\n",
    "try:\n",
    "    command = sextractor_command\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run SExtractor with exit error %s'%err)\n",
    "\n",
    "cat_sci = ascii.read('sci_match.cat')\n",
    "\n",
    "\n",
    "#Run SExtractor on the reference image\n",
    "sextractor_command = \"sextractor ref_convolved.fits -c prepsfex.sex -CATALOG_NAME ref_match.cat -MAG_ZEROPOINT 25.0 -CATALOG_TYPE=ASCII_HEAD\"\n",
    "\n",
    "try:\n",
    "    command = sextractor_command\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run SExtractor with exit error %s'%err)\n",
    "cat_ref=ascii.read('ref_match.cat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the catalog of sources of the reference and science images.  Calculate the ratio between the flux of source in the science image over the flux of sources in the reference image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = SkyCoord(ra=cat_sci['X_WORLD'], dec=cat_sci['Y_WORLD'])\n",
    "c2 = SkyCoord(ra=cat_ref['X_WORLD'], dec=cat_ref['Y_WORLD'])\n",
    "\n",
    "#print(c1)\n",
    "idx, d2d, d3d = c1.match_to_catalog_3d(c2)\n",
    "\n",
    "index_arr = []\n",
    "ratio_arr = []\n",
    "for i, i2, d in zip(idx, np.arange(len(d2d)),d2d):\n",
    "    #print(i,d)\n",
    "    index_arr.append(i)\n",
    "    print(cat_ref['X_IMAGE'][i],cat_ref['Y_IMAGE'][i],'  ', cat_sci['X_IMAGE'][i2],cat_sci['Y_IMAGE'][i2])\n",
    "    print(cat_ref['FLUX_AUTO'][i], cat_sci['FLUX_AUTO'][i2]   )\n",
    "    ratio_arr.append(cat_sci['FLUX_AUTO'][i2] / cat_ref['FLUX_AUTO'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "1. Find the scaling factor \n",
    "2. Rescale the science image and perform the image subtraction.\n",
    "3. Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the scaling factor\n",
    "scale = ???\n",
    "print(\"The scaling factor is\", scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescale the science image and perform the image subtraction.\n",
    "\n",
    "image_sub = ???\n",
    "hdu_image_sub = fits.PrimaryHDU(image_sub)\n",
    "hdu_image_sub.writeto(\"sub_final.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot up the result of the image subtraction\n",
    "???\n",
    "plt.title('Final image subtraction')\n",
    "plt.show()\n",
    "\n",
    "#...and plot up the same region of sky of science and template images\n",
    "mean, median, std = sigma_clipped_stats(sci_conv_shift)\n",
    "plt.figure(figsize=(8,8))\n",
    "#set the scale of the image based on its statistics\n",
    "plt.imshow(sci_conv_shift[200:600,1100:1600], vmin = median - 3*std, vmax = median + 3*std, cmap='gray')\n",
    "plt.plot([280,310],[115,115], \"r-\" )\n",
    "plt.plot([258,258],[95,65], \"r-\" )\n",
    "plt.colorbar(shrink = 0.4)\n",
    "plt.title('Science image')\n",
    "plt.show()\n",
    "\n",
    "mean, median, std = sigma_clipped_stats(ref_conv)\n",
    "plt.figure(figsize=(8,8))\n",
    "#set the scale of the image based on its statistics\n",
    "plt.imshow(ref_conv[200:600,1100:1600], vmin = median - 3*std, vmax = median + 3*std, cmap='gray')\n",
    "plt.plot([280,310],[115,115], \"r-\" )\n",
    "plt.plot([258,258],[95,65], \"r-\" )\n",
    "plt.colorbar(shrink = 0.4)\n",
    "plt.title('Reference image')\n",
    "plt.show()\n",
    "\n",
    "#ds9 visualization\n",
    "#os.system('ds9 '+sci_image_aligned_name +' ' + ref_image_aligned_name + ' sub_final.fits &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go, now you should be able to easily spot the supernova as a white excess on the grey background! <br >\n",
    "\n",
    "Note that the bright center of the host galaxy was not perfectly subtracted and left a spurious signal that could be mistaken for real luminosity variability.  <br >\n",
    "\n",
    "\n",
    "These operations can be made automatic and can be incorporated in pipelines that discover transients.  Moreover, using the methods learnt in the Photometry module, you can perform forced PSF photometry on the image subtraction to obtain flux measurement of the transient free from the host galaxy contamination.\n",
    "\n",
    "# END OF THE SCHOOL MODULE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:  HOTPANTS\n",
    "\n",
    "There are some packages that perform most of the operations above automatically.  One of the most popular is called HOTPANTS, which stands for \"High Order Transform of PSF ANd Template Subtraction\". <br >\n",
    "\n",
    "The code can be found on GitHub: https://github.com/acbecker/hotpants <br >  To proceed, install this program and continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hotpants\n",
    "os.system(\"path/to/hotpants -inim\"+\" \"+sci_image_aligned_name+\" \"+\"-tmplim \"+ref_image_aligned_name+\" -outim out.fits -oci oci.fits -tg 1 -tr 1 -ig 1 -ir 1 -nrx 1 -nry 1 -nsx 2 -nsy 2 -ng 3 6 0.70 4 1.50 2 3.00 -v 0 -bgo 0 -tl 1 -tu 150000 -il 1 -iu 150000 -ko 0\")\n",
    "\n",
    "hotpants_image = fits.open('oci.fits')\n",
    "image_sub = hotpants_image[0].data-ref_image_aligned[0].data*0.975\n",
    "hdu_image_sub = fits.PrimaryHDU(image_sub)\n",
    "hdu_image_sub.writeto(\"sub_test_hp.fits\", overwrite = True)\n",
    "os.system('ds9 sub_test_hp.fits &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:  Convolving one image only\n",
    "We can also perform image subtraction after degrading (i.e., convolving with a kernel) only one of the two images. In fact, in some cases it is preferred to keep the science image untouched and manipulate only the reference to avoid introducing errors in photometry measurements.  On the other hand, convolving both images usually leads to \"cleaner\" image subtraction.\n",
    "\n",
    "Below are a list of commands to do a better job with manipulating only one image usinf fft techniques. In this example, we manipulate the science image instead of the reference simply because of what the specific characteristics of the images that we are playing with.  Identical methods can be applied to manipulating reference images only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively to degrade one image only\n",
    "Im1_psf = np.fft.fftshift(kernel_ref);\n",
    "Im2_psf = np.fft.fftshift(kernel_sci);\n",
    "\n",
    "psf_fft1 = np.fft.fft2(Im1_psf);\n",
    "psf_fft2 = np.fft.fft2(Im2_psf);\n",
    "\n",
    "\n",
    "kern = psf_fft1/psf_fft2;\n",
    "kern_m = np.real(np.fft.fftshift(np.fft.ifft2(kern)))\n",
    "kern_mean = np.mean(kern_m)\n",
    "psf_m = (kern_m/(kern_mean*59*59))\n",
    "\n",
    "plt.imshow(psf_m, cmap='gray')\n",
    "\n",
    "sci_conv = scipy_convolve(sci_image_aligned[0].data, psf_m, mode='same', method='fft')\n",
    "\n",
    "from image_registration import chi2_shift\n",
    "from image_registration.fft_tools import shift\n",
    "import scipy\n",
    "from scipy import ndimage, misc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.fft\n",
    "\n",
    "xoff, yoff, exoff, eyoff = chi2_shift(ref_image_aligned[0].data, sci_conv, 10, return_error=True, upsample_factor='auto')\n",
    "print(xoff,yoff)\n",
    "\n",
    "sci_conv_shift = scipy.ndimage.shift(sci_conv, [-yoff, -xoff], order=3, mode='reflect', cval=0.0, prefilter=True)\n",
    "                 \n",
    "image_sub = sci_conv_shift*scale-ref_image_aligned[0].data\n",
    "hdu_image_sub = fits.PrimaryHDU(image_sub)\n",
    "hdu_image_sub.writeto(\"sub_test2.fits\", overwrite = True)\n",
    "\n",
    "os.system('ds9 sub_test2.fits&')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
